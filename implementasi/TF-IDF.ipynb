{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset_1 = pd.read_csv('data/dataset1_preprocessing.csv') \n",
    "dataset_2 = pd.read_csv('data/dataset2_preprocessing.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TF-IDF of Dataset 1</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>length</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NTSB says Autopilot engaged in 2018 California...</td>\n",
       "      <td>The National Transportation Safety Board said ...</td>\n",
       "      <td>WASHINGTON (Reuters) - The National Transporta...</td>\n",
       "      <td>578</td>\n",
       "      <td>['ntsb', 'says', 'autopilot', 'engaged', 'cali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unemployment falls to post-crash low of 5.2%</td>\n",
       "      <td>Latest monthly figures reflect continued growt...</td>\n",
       "      <td>The States jobless rate fell to 5.2 per cent l...</td>\n",
       "      <td>387</td>\n",
       "      <td>['unemployment', 'falls', 'post', 'crash', 'low']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Louise Kennedy AW2019: Long coats, sparkling t...</td>\n",
       "      <td>Autumn-winter collection features designer’s g...</td>\n",
       "      <td>Louise Kennedy is showing off her autumn-winte...</td>\n",
       "      <td>432</td>\n",
       "      <td>['louise', 'kennedy', 'aw2019', 'long', 'coats...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North Korean footballer Han joins Italian gian...</td>\n",
       "      <td>Han is the first North Korean player in the Se...</td>\n",
       "      <td>Han Kwang Song, the first North Korean footbal...</td>\n",
       "      <td>446</td>\n",
       "      <td>['north', 'korean', 'footballer', 'han', 'join...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'This Tender Land' is an affecting story about...</td>\n",
       "      <td>\"This Tender Land\" by William Kent Krueger is ...</td>\n",
       "      <td>\"This Tender Land: a Novel\" (Atria Books), by ...</td>\n",
       "      <td>500</td>\n",
       "      <td>['tender', 'land', 'affecting', 'story', 'grow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  NTSB says Autopilot engaged in 2018 California...   \n",
       "1       Unemployment falls to post-crash low of 5.2%   \n",
       "2  Louise Kennedy AW2019: Long coats, sparkling t...   \n",
       "3  North Korean footballer Han joins Italian gian...   \n",
       "4  'This Tender Land' is an affecting story about...   \n",
       "\n",
       "                                         description  \\\n",
       "0  The National Transportation Safety Board said ...   \n",
       "1  Latest monthly figures reflect continued growt...   \n",
       "2  Autumn-winter collection features designer’s g...   \n",
       "3  Han is the first North Korean player in the Se...   \n",
       "4  \"This Tender Land\" by William Kent Krueger is ...   \n",
       "\n",
       "                                             content  length  \\\n",
       "0  WASHINGTON (Reuters) - The National Transporta...     578   \n",
       "1  The States jobless rate fell to 5.2 per cent l...     387   \n",
       "2  Louise Kennedy is showing off her autumn-winte...     432   \n",
       "3  Han Kwang Song, the first North Korean footbal...     446   \n",
       "4  \"This Tender Land: a Novel\" (Atria Books), by ...     500   \n",
       "\n",
       "                                             article  \n",
       "0  ['ntsb', 'says', 'autopilot', 'engaged', 'cali...  \n",
       "1  ['unemployment', 'falls', 'post', 'crash', 'low']  \n",
       "2  ['louise', 'kennedy', 'aw2019', 'long', 'coats...  \n",
       "3  ['north', 'korean', 'footballer', 'han', 'join...  \n",
       "4  ['tender', 'land', 'affecting', 'story', 'grow...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gregor', 'townsend', 'believes', 'scotland', 'never', 'better', 'position']\n",
      "\n",
      "type :  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# convert list formated string to list\n",
    "import ast\n",
    "\n",
    "def convert_text_list(texts):\n",
    "    texts = ast.literal_eval(texts)\n",
    "    return [text for text in texts]\n",
    "\n",
    "dataset_1[\"article_list\"] = dataset_1[\"article\"].apply(convert_text_list)\n",
    "\n",
    "\n",
    "print(dataset_1[\"article_list\"][90])\n",
    "\n",
    "print(\"\\ntype : \", type(dataset_1[\"article_list\"][90]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'ntsb': 0.14285714285714285, 'says': 0.142857...\n",
       "1    {'unemployment': 0.2, 'falls': 0.2, 'post': 0....\n",
       "2    {'louise': 0.1, 'kennedy': 0.1, 'aw2019': 0.1,...\n",
       "3    {'north': 0.125, 'korean': 0.125, 'footballer'...\n",
       "4    {'tender': 0.2, 'land': 0.2, 'affecting': 0.2,...\n",
       "Name: TF_dict, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_TF(document):\n",
    "    # Counts the number of times the word appears in review\n",
    "    TF_dict = {}\n",
    "    for term in document:\n",
    "        if term in TF_dict:\n",
    "            TF_dict[term] += 1\n",
    "        else:\n",
    "            TF_dict[term] = 1\n",
    "    # Computes tf for each word\n",
    "    for term in TF_dict:\n",
    "        TF_dict[term] = TF_dict[term] / len(document)\n",
    "    return TF_dict\n",
    "\n",
    "dataset_1[\"TF_dict\"] = dataset_1['article_list'].apply(calc_TF)\n",
    "\n",
    "dataset_1[\"TF_dict\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                term \t TF\n",
      "\n",
      "              gregor \t 0.14285714285714285\n",
      "            townsend \t 0.14285714285714285\n",
      "            believes \t 0.14285714285714285\n",
      "            scotland \t 0.14285714285714285\n",
      "               never \t 0.14285714285714285\n",
      "              better \t 0.14285714285714285\n",
      "            position \t 0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "# Check TF result\n",
    "index = 90\n",
    "\n",
    "print('%20s' % \"term\", \"\\t\", \"TF\\n\")\n",
    "for key in dataset_1[\"TF_dict\"][index]:\n",
    "    print('%20s' % key, \"\\t\", dataset_1[\"TF_dict\"][index][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ntsb': 8,\n",
       " 'says': 440,\n",
       " 'autopilot': 4,\n",
       " 'engaged': 2,\n",
       " 'california': 77,\n",
       " 'tesla': 22,\n",
       " 'crash': 53,\n",
       " 'unemployment': 4,\n",
       " 'falls': 14,\n",
       " 'post': 32,\n",
       " 'low': 39,\n",
       " 'louise': 4,\n",
       " 'kennedy': 11,\n",
       " 'aw2019': 3,\n",
       " 'long': 40,\n",
       " 'coats': 2,\n",
       " 'sparkling': 3,\n",
       " 'tweed': 3,\n",
       " 'dresses': 2,\n",
       " 'emerald': 3,\n",
       " 'knits': 3,\n",
       " 'north': 70,\n",
       " 'korean': 10,\n",
       " 'footballer': 2,\n",
       " 'han': 1,\n",
       " 'joins': 11,\n",
       " 'italian': 23,\n",
       " 'giants': 8,\n",
       " 'juventus': 5,\n",
       " 'tender': 2,\n",
       " 'land': 11,\n",
       " 'affecting': 3,\n",
       " 'story': 35,\n",
       " 'growing': 15,\n",
       " 'eu': 80,\n",
       " 'wants': 43,\n",
       " 'see': 33,\n",
       " 'lawmakers': 16,\n",
       " 'block': 23,\n",
       " 'brexit': 243,\n",
       " 'striking': 5,\n",
       " 'new': 498,\n",
       " 'deal': 163,\n",
       " 'uks': 12,\n",
       " 'johnson': 142,\n",
       " 'european': 21,\n",
       " 'third': 32,\n",
       " 'quarter': 22,\n",
       " 'profit': 11,\n",
       " 'outlook': 11,\n",
       " 'improves': 5,\n",
       " 'slightly': 1,\n",
       " 'still': 57,\n",
       " 'recession': 25,\n",
       " 'refinitv': 1,\n",
       " 'emotional': 6,\n",
       " 'support': 41,\n",
       " 'animals': 10,\n",
       " 'allowed': 9,\n",
       " 'flights': 19,\n",
       " 'boris': 84,\n",
       " 'meet': 44,\n",
       " 'leo': 3,\n",
       " 'varadkar': 16,\n",
       " 'dublin': 49,\n",
       " 'monday': 18,\n",
       " 'afghan': 13,\n",
       " 'peace': 32,\n",
       " 'bring': 21,\n",
       " 'people': 90,\n",
       " 'daniil': 3,\n",
       " 'medvedev': 9,\n",
       " 'rides': 5,\n",
       " 'wave': 13,\n",
       " 'hostility': 2,\n",
       " 'us': 615,\n",
       " 'open': 70,\n",
       " 'marks': 6,\n",
       " 'spencer': 3,\n",
       " 'kicked': 4,\n",
       " 'ftse': 3,\n",
       " 'first': 142,\n",
       " 'time': 87,\n",
       " 'neil': 7,\n",
       " 'lennon': 2,\n",
       " 'celtic': 11,\n",
       " 'manager': 20,\n",
       " 'pleased': 4,\n",
       " 'clubs': 6,\n",
       " 'transfer': 1,\n",
       " 'business': 78,\n",
       " 'putney': 1,\n",
       " 'child': 30,\n",
       " 'murder': 64,\n",
       " 'suspects': 5,\n",
       " 'detained': 7,\n",
       " 'police': 157,\n",
       " 'attack': 78,\n",
       " 'school': 69,\n",
       " 'china': 138,\n",
       " 'leaves': 24,\n",
       " 'least': 30,\n",
       " 'children': 29,\n",
       " 'dead': 74,\n",
       " 'coast': 33,\n",
       " 'guard': 19,\n",
       " 'suspends': 5,\n",
       " 'search': 20,\n",
       " 'efforts': 11,\n",
       " 'victims': 30,\n",
       " 'deadly': 27,\n",
       " 'boat': 45,\n",
       " 'fire': 82,\n",
       " 'exchequer': 1,\n",
       " 'boost': 27,\n",
       " 'government': 86,\n",
       " 'ahead': 52,\n",
       " 'budget': 17,\n",
       " 'netflix': 13,\n",
       " 'dark': 5,\n",
       " 'crystal': 3,\n",
       " 'age': 22,\n",
       " 'resistance': 1,\n",
       " 'review': 95,\n",
       " 'muppets': 1,\n",
       " 'game': 40,\n",
       " 'thrones': 2,\n",
       " 'latest': 108,\n",
       " 'updates': 30,\n",
       " 'natural': 5,\n",
       " 'wines': 2,\n",
       " 'get': 97,\n",
       " 'showcases': 4,\n",
       " 'fall': 43,\n",
       " 'competition': 5,\n",
       " 'collaboration': 2,\n",
       " 'paypal': 1,\n",
       " 'turned': 6,\n",
       " 'challengers': 3,\n",
       " 'like': 107,\n",
       " 'visa': 4,\n",
       " 'mastercard': 2,\n",
       " 'partners': 9,\n",
       " 'started': 6,\n",
       " 'sharing': 3,\n",
       " 'data': 46,\n",
       " 'drive': 16,\n",
       " 'even': 24,\n",
       " 'trial': 41,\n",
       " 'actor': 6,\n",
       " 'cuba': 2,\n",
       " 'gooding': 2,\n",
       " 'jr': 6,\n",
       " 'groping': 3,\n",
       " 'case': 65,\n",
       " 'gets': 54,\n",
       " 'october': 19,\n",
       " 'date': 14,\n",
       " 'interpreting': 1,\n",
       " 'interpreter': 1,\n",
       " 'lafcadio': 1,\n",
       " 'hearn': 1,\n",
       " 'indias': 17,\n",
       " 'chandrayaan': 4,\n",
       " 'ready': 29,\n",
       " 'moon': 18,\n",
       " 'landing': 8,\n",
       " 'woman': 86,\n",
       " 'survives': 1,\n",
       " 'foot': 9,\n",
       " 'cliff': 2,\n",
       " 'south': 63,\n",
       " 'dakota': 6,\n",
       " 'state': 61,\n",
       " 'park': 17,\n",
       " 'philadelphia': 2,\n",
       " 'district': 9,\n",
       " 'attorney': 11,\n",
       " 'exonerates': 1,\n",
       " 'months': 28,\n",
       " 'keith': 3,\n",
       " 'hill': 3,\n",
       " 'bolton': 36,\n",
       " 'wanderers': 2,\n",
       " 'boss': 24,\n",
       " 'wont': 30,\n",
       " 'mentally': 1,\n",
       " 'ruin': 1,\n",
       " 'young': 32,\n",
       " 'players': 27,\n",
       " 'trump': 453,\n",
       " 'said': 22,\n",
       " 'skipped': 1,\n",
       " 'diplomatic': 8,\n",
       " 'trip': 14,\n",
       " 'monitor': 8,\n",
       " 'hurricane': 134,\n",
       " 'dorian': 143,\n",
       " 'spent': 8,\n",
       " 'weekend': 21,\n",
       " 'golfing': 3,\n",
       " 'illinois': 7,\n",
       " 'lawsuit': 17,\n",
       " 'ask': 11,\n",
       " 'court': 98,\n",
       " 'stop': 41,\n",
       " 'merger': 3,\n",
       " 'mobile': 22,\n",
       " 'sprint': 3,\n",
       " 'weakened': 3,\n",
       " 'category': 6,\n",
       " 'storm': 59,\n",
       " 'maximum': 5,\n",
       " 'sustained': 1,\n",
       " 'winds': 8,\n",
       " 'near': 43,\n",
       " 'mph': 6,\n",
       " 'kph': 1,\n",
       " 'much': 36,\n",
       " 'tougher': 6,\n",
       " 'elected': 4,\n",
       " 'israel': 19,\n",
       " 'sends': 14,\n",
       " 'firefighters': 5,\n",
       " 'help': 56,\n",
       " 'brazil': 23,\n",
       " 'battle': 25,\n",
       " 'amazon': 64,\n",
       " 'fires': 32,\n",
       " 'pence': 14,\n",
       " 'faces': 43,\n",
       " 'row': 16,\n",
       " 'stay': 28,\n",
       " 'irish': 90,\n",
       " 'resort': 26,\n",
       " 'jofra': 3,\n",
       " 'archer': 4,\n",
       " 'slides': 5,\n",
       " 'across': 24,\n",
       " 'pitch': 9,\n",
       " 'football': 52,\n",
       " 'match': 18,\n",
       " 'teammates': 2,\n",
       " 'defends': 23,\n",
       " 'decision': 23,\n",
       " 'doonbeg': 5,\n",
       " 'property': 9,\n",
       " 'private': 28,\n",
       " 'equity': 3,\n",
       " 'giant': 21,\n",
       " 'carlyle': 1,\n",
       " 'taking': 21,\n",
       " 'majority': 10,\n",
       " 'stake': 7,\n",
       " 'startup': 26,\n",
       " 'uses': 7,\n",
       " 'ai': 8,\n",
       " 'judge': 43,\n",
       " 'smile': 1,\n",
       " 'interviews': 4,\n",
       " 'could': 144,\n",
       " 'future': 39,\n",
       " 'recruiting': 3,\n",
       " 'border': 67,\n",
       " 'cross': 7,\n",
       " 'frank': 19,\n",
       " 'mcnally': 6,\n",
       " 'stresses': 1,\n",
       " 'driving': 11,\n",
       " 'former': 89,\n",
       " 'yugoslavia': 1,\n",
       " 'edge': 12,\n",
       " 'turkey': 30,\n",
       " 'canada': 35,\n",
       " 'eliminated': 1,\n",
       " 'world': 182,\n",
       " 'cup': 108,\n",
       " 'justin': 20,\n",
       " 'bieber': 4,\n",
       " 'childhood': 3,\n",
       " 'fame': 4,\n",
       " 'opened': 5,\n",
       " 'door': 5,\n",
       " 'heavy': 9,\n",
       " 'drug': 28,\n",
       " 'use': 42,\n",
       " 'alyssa': 4,\n",
       " 'milano': 4,\n",
       " 'slammed': 5,\n",
       " 'saying': 9,\n",
       " 'shes': 6,\n",
       " 'fighting': 18,\n",
       " 'americans': 24,\n",
       " 'rights': 29,\n",
       " 'opponents': 2,\n",
       " 'argue': 4,\n",
       " 'commons': 6,\n",
       " 'control': 31,\n",
       " 'phones': 5,\n",
       " 'buzz': 1,\n",
       " 'class—with': 1,\n",
       " 'texts': 2,\n",
       " 'mom': 12,\n",
       " 'dad': 9,\n",
       " 'opioid': 17,\n",
       " 'litigation': 1,\n",
       " 'proceed': 1,\n",
       " 'toward': 11,\n",
       " 'flight': 19,\n",
       " 'cancellations': 2,\n",
       " 'reach': 18,\n",
       " 'nearly': 26,\n",
       " 'routes': 1,\n",
       " 'delayed': 6,\n",
       " 'prince': 23,\n",
       " 'harry': 18,\n",
       " 'launches': 33,\n",
       " 'sustainable': 2,\n",
       " 'travel': 19,\n",
       " 'initiative': 4,\n",
       " 'jet': 12,\n",
       " 'criticism': 16,\n",
       " 'chinese': 29,\n",
       " 'deepfake': 2,\n",
       " 'app': 29,\n",
       " 'zao': 1,\n",
       " 'comes': 21,\n",
       " 'privacy': 8,\n",
       " 'concerns': 16,\n",
       " 'streaming': 14,\n",
       " 'services': 25,\n",
       " 'draw': 7,\n",
       " 'subscribers': 5,\n",
       " 'old': 78,\n",
       " 'rock': 9,\n",
       " 'roll': 9,\n",
       " 'att': 13,\n",
       " 'makes': 40,\n",
       " 'warnermedia': 3,\n",
       " 'john': 50,\n",
       " 'stankey': 4,\n",
       " 'presumptive': 1,\n",
       " 'successor': 4,\n",
       " 'ceo': 50,\n",
       " 'air': 45,\n",
       " 'files': 11,\n",
       " 'challenge': 29,\n",
       " 'onexs': 2,\n",
       " 'c35': 2,\n",
       " 'billion': 71,\n",
       " 'buyout': 2,\n",
       " 'rival': 14,\n",
       " 'westjet': 2,\n",
       " 'food': 34,\n",
       " 'jobs': 37,\n",
       " 'away': 28,\n",
       " 'hondurans': 4,\n",
       " 'say': 87,\n",
       " 'struggling': 3,\n",
       " 'survive': 8,\n",
       " 'bangladesh': 6,\n",
       " 'blocks': 10,\n",
       " 'internet': 12,\n",
       " 'rohingya': 4,\n",
       " 'refugee': 8,\n",
       " 'camps': 5,\n",
       " 'restart': 3,\n",
       " 'xbox': 4,\n",
       " 'one': 144,\n",
       " 'console': 2,\n",
       " 'controller': 3,\n",
       " 'shut': 3,\n",
       " 'pottery': 1,\n",
       " 'barn': 1,\n",
       " 'teens': 8,\n",
       " 'fantastic': 2,\n",
       " 'beasts': 1,\n",
       " 'collection': 11,\n",
       " 'features': 16,\n",
       " 'decor': 1,\n",
       " 'bedding': 1,\n",
       " 'potter': 3,\n",
       " 'fans': 25,\n",
       " 'love': 30,\n",
       " 'hong': 114,\n",
       " 'kong': 108,\n",
       " 'targets': 10,\n",
       " 'pro': 22,\n",
       " 'democracy': 15,\n",
       " 'activists': 17,\n",
       " 'amid': 72,\n",
       " 'protests': 59,\n",
       " 'dying': 8,\n",
       " 'home': 75,\n",
       " 'overrated': 1,\n",
       " 'nie': 1,\n",
       " 'yuanzi': 1,\n",
       " 'whose': 3,\n",
       " 'poster': 3,\n",
       " 'fanned': 1,\n",
       " 'cultural': 3,\n",
       " 'revolution': 4,\n",
       " 'dies': 101,\n",
       " 'oklahoma': 7,\n",
       " 'man': 198,\n",
       " 'hurls': 1,\n",
       " 'cupcake': 1,\n",
       " 'car': 61,\n",
       " 'hits': 36,\n",
       " 'driver': 23,\n",
       " 'face': 51,\n",
       " 'charged': 50,\n",
       " 'assault': 20,\n",
       " 'pushing': 3,\n",
       " 'labels': 3,\n",
       " 'consumers': 7,\n",
       " 'add': 14,\n",
       " 'competing': 2,\n",
       " 'products': 20,\n",
       " 'carts': 1,\n",
       " 'amzn': 12,\n",
       " 'stocks': 56,\n",
       " 'drop': 21,\n",
       " 'signs': 20,\n",
       " 'trouble': 4,\n",
       " 'manufacturing': 9,\n",
       " 'walmart': 30,\n",
       " 'ends': 9,\n",
       " 'handgun': 2,\n",
       " 'ammunition': 9,\n",
       " 'sales': 35,\n",
       " 'asks': 15,\n",
       " 'customers': 13,\n",
       " 'carry': 7,\n",
       " 'guns': 16,\n",
       " 'stores': 16,\n",
       " 'budge': 2,\n",
       " 'bahamas': 82,\n",
       " 'hammered': 3,\n",
       " 'slow': 11,\n",
       " 'moving': 10,\n",
       " 'sources': 34,\n",
       " 'urgency': 2,\n",
       " 'zeke': 1,\n",
       " 'talks': 105,\n",
       " 'rb': 5,\n",
       " 'flying': 9,\n",
       " 'back': 94,\n",
       " 'paying': 5,\n",
       " 'debit': 1,\n",
       " 'card': 22,\n",
       " 'leaving': 10,\n",
       " 'money': 48,\n",
       " 'table': 3,\n",
       " 'reasons': 6,\n",
       " 'ever': 36,\n",
       " 'pay': 53,\n",
       " 'credit': 26,\n",
       " 'limerick': 6,\n",
       " 'nursing': 2,\n",
       " 'failed': 12,\n",
       " 'investigate': 26,\n",
       " 'allegation': 9,\n",
       " 'abuse': 39,\n",
       " 'venezuelan': 3,\n",
       " 'oil': 97,\n",
       " 'exports': 14,\n",
       " 'lowest': 10,\n",
       " 'level': 18,\n",
       " 'sanctions': 13,\n",
       " 'bite': 5,\n",
       " 'tuesday': 11,\n",
       " 'briefing': 35,\n",
       " 'student': 24,\n",
       " 'arrested': 49,\n",
       " 'noose': 2,\n",
       " 'found': 76,\n",
       " 'elevator': 4,\n",
       " 'justice': 29,\n",
       " 'sotomayor': 4,\n",
       " 'encourages': 1,\n",
       " 'kids': 29,\n",
       " 'book': 24,\n",
       " 'uk': 125,\n",
       " 'public': 31,\n",
       " 'must': 31,\n",
       " 'decide': 13,\n",
       " 'next': 65,\n",
       " 'steps': 15,\n",
       " 'parliament': 45,\n",
       " 'votes': 13,\n",
       " 'pms': 7,\n",
       " 'spokesman': 11,\n",
       " 'ariana': 3,\n",
       " 'grande': 3,\n",
       " 'forever': 14,\n",
       " 'stole': 4,\n",
       " 'name': 25,\n",
       " 'nintendo': 11,\n",
       " 'direct': 9,\n",
       " 'predictions': 8,\n",
       " 'smash': 1,\n",
       " 'ultimate': 4,\n",
       " 'dlc': 1,\n",
       " 'pokémon': 6,\n",
       " 'sword': 5,\n",
       " 'shield': 4,\n",
       " 'starter': 3,\n",
       " 'evolutions': 1,\n",
       " 'construction': 9,\n",
       " 'spending': 18,\n",
       " 'rose': 7,\n",
       " 'slight': 3,\n",
       " 'july': 12,\n",
       " 'italys': 16,\n",
       " 'star': 48,\n",
       " 'favor': 8,\n",
       " 'pd': 3,\n",
       " 'coalition': 14,\n",
       " 'opening': 15,\n",
       " 'way': 40,\n",
       " 'euro': 20,\n",
       " 'qualifiers': 7,\n",
       " 'aaron': 4,\n",
       " 'wan': 1,\n",
       " 'bissaka': 1,\n",
       " 'england': 39,\n",
       " 'squad': 14,\n",
       " 'injury': 17,\n",
       " 'drivers': 8,\n",
       " 'reportedly': 44,\n",
       " 'locked': 6,\n",
       " 'cars': 18,\n",
       " 'goes': 26,\n",
       " 'cloudflare': 1,\n",
       " 'eyes': 11,\n",
       " 'valuation': 14,\n",
       " 'upcoming': 8,\n",
       " 'ipo': 34,\n",
       " 'deaths': 28,\n",
       " 'mount': 5,\n",
       " 'france': 41,\n",
       " 'tries': 18,\n",
       " 'serious': 8,\n",
       " 'domestic': 10,\n",
       " 'violence': 33,\n",
       " 'path': 17,\n",
       " 'map': 15,\n",
       " 'update': 61,\n",
       " 'storms': 3,\n",
       " 'movement': 7,\n",
       " 'make': 65,\n",
       " 'destructive': 1,\n",
       " 'experts': 19,\n",
       " 'real': 48,\n",
       " 'cost': 30,\n",
       " 'blue': 10,\n",
       " 'jeans': 3,\n",
       " 'feds': 12,\n",
       " 'offers': 15,\n",
       " 'reprieve': 1,\n",
       " 'immigrant': 4,\n",
       " 'medical': 25,\n",
       " 'care': 19,\n",
       " 'cases': 20,\n",
       " 'would': 49,\n",
       " 'losses': 5,\n",
       " 'un': 46,\n",
       " 'im': 18,\n",
       " 'steve': 10,\n",
       " 'smith': 12,\n",
       " 'greenhouse': 3,\n",
       " 'large': 5,\n",
       " 'enough': 10,\n",
       " 'feed': 2,\n",
       " 'eastern': 5,\n",
       " 'seaboard': 1,\n",
       " 'guinea': 2,\n",
       " 'bissau': 1,\n",
       " 'tonnes': 5,\n",
       " 'cocaine': 4,\n",
       " 'seized': 3,\n",
       " 'biggest': 41,\n",
       " 'haul': 6,\n",
       " 'beach': 11,\n",
       " 'wastewater': 2,\n",
       " 'plant': 21,\n",
       " 'blanketed': 1,\n",
       " 'noxious': 1,\n",
       " 'material': 1,\n",
       " 'applies': 1,\n",
       " 'license': 5,\n",
       " 'turkish': 13,\n",
       " 'broadcasting': 1,\n",
       " 'rules': 32,\n",
       " 'stalls': 5,\n",
       " 'couple': 15,\n",
       " 'burglary': 6,\n",
       " 'years': 92,\n",
       " '500k': 1,\n",
       " 'lottery': 3,\n",
       " 'win': 81,\n",
       " 'manchin': 5,\n",
       " 'decides': 2,\n",
       " 'running': 23,\n",
       " 'west': 33,\n",
       " 'virginia': 22,\n",
       " 'governor': 17,\n",
       " 'senate': 21,\n",
       " 'gregor': 1,\n",
       " 'townsend': 1,\n",
       " 'believes': 3,\n",
       " 'scotland': 39,\n",
       " 'never': 27,\n",
       " 'better': 26,\n",
       " 'position': 6,\n",
       " 'designer': 5,\n",
       " 'bringing': 7,\n",
       " 'whimsy': 1,\n",
       " 'magic': 2,\n",
       " 'mushrooms': 3,\n",
       " 'fine': 14,\n",
       " 'jewelry': 3,\n",
       " 'bodies': 8,\n",
       " 'recovered': 3,\n",
       " 'jeffrey': 12,\n",
       " 'epstein': 14,\n",
       " 'york': 96,\n",
       " 'hunting': 6,\n",
       " 'ground': 15,\n",
       " 'dance': 8,\n",
       " 'studios': 4,\n",
       " 'elephant': 3,\n",
       " 'castle': 5,\n",
       " 'stabbings': 2,\n",
       " 'norman': 3,\n",
       " 'bertran': 1,\n",
       " 'tavarez': 1,\n",
       " 'named': 20,\n",
       " 'victim': 20,\n",
       " 'dogs': 9,\n",
       " 'cats': 2,\n",
       " 'making': 40,\n",
       " 'shelters': 3,\n",
       " 'alive': 6,\n",
       " 'melvin': 1,\n",
       " 'gordon': 4,\n",
       " 'holdout': 2,\n",
       " 'los': 9,\n",
       " 'angeles': 7,\n",
       " 'chargers': 3,\n",
       " 'play': 31,\n",
       " 'year': 170,\n",
       " 't20': 5,\n",
       " 'qualifier': 5,\n",
       " 'thailand': 2,\n",
       " 'claim': 39,\n",
       " 'two': 77,\n",
       " 'run': 27,\n",
       " 'ireland': 145,\n",
       " 'women': 56,\n",
       " 'picture': 7,\n",
       " 'instagram': 19,\n",
       " 'perfect': 9,\n",
       " 'hotel': 22,\n",
       " 'views': 6,\n",
       " 'african': 24,\n",
       " 'arrests': 10,\n",
       " 'riots': 4,\n",
       " 'spread': 8,\n",
       " 'booker': 8,\n",
       " 'prize': 16,\n",
       " 'margaret': 12,\n",
       " 'atwood': 11,\n",
       " 'salman': 4,\n",
       " 'rushdie': 6,\n",
       " 'strong': 16,\n",
       " 'shortlist': 5,\n",
       " 'gmt': 90,\n",
       " 'supporters': 7,\n",
       " 'plan': 94,\n",
       " 'democrats': 58,\n",
       " 'online': 30,\n",
       " 'vote': 27,\n",
       " 'ambassador': 8,\n",
       " 'tech': 52,\n",
       " 'industry': 18,\n",
       " 'times': 89,\n",
       " 'uaw': 15,\n",
       " 'workers': 54,\n",
       " 'authorize': 1,\n",
       " 'strikes': 22,\n",
       " 'detroit': 4,\n",
       " 'hezbollah': 8,\n",
       " 'plans': 69,\n",
       " 'advanced': 7,\n",
       " 'missile': 19,\n",
       " 'lebanons': 5,\n",
       " 'bekaa': 2,\n",
       " 'weakens': 2,\n",
       " 'bought': 7,\n",
       " '€112m': 1,\n",
       " 'lotto': 1,\n",
       " 'ticket': 5,\n",
       " 'change': 57,\n",
       " 'chicken': 13,\n",
       " 'fillet': 1,\n",
       " 'bts': 1,\n",
       " 'create': 6,\n",
       " 'forest': 10,\n",
       " 'seoul': 1,\n",
       " 'celebrate': 12,\n",
       " 'rms': 1,\n",
       " 'birthday': 12,\n",
       " 'convicted': 17,\n",
       " 'hacker': 3,\n",
       " 'called': 17,\n",
       " 'testify': 3,\n",
       " 'grand': 25,\n",
       " 'jury': 22,\n",
       " 'dive': 14,\n",
       " 'company': 51,\n",
       " 'owner': 16,\n",
       " 'among': 20,\n",
       " 'missing': 29,\n",
       " 'pound': 4,\n",
       " 'sinks': 3,\n",
       " 'three': 46,\n",
       " 'election': 86,\n",
       " 'threat': 26,\n",
       " 'adds': 14,\n",
       " 'jeopardy': 5,\n",
       " 'texas': 47,\n",
       " 'popeyes': 6,\n",
       " 'ran': 3,\n",
       " 'sandwiches': 3,\n",
       " 'pulls': 9,\n",
       " 'gun': 56,\n",
       " 'atlanta': 3,\n",
       " 'comfort': 2,\n",
       " 'evacuees': 5,\n",
       " 'free': 39,\n",
       " 'cnn': 49,\n",
       " 'mistakenly': 2,\n",
       " 'alabama': 36,\n",
       " 'mississippi': 7,\n",
       " 'mocking': 2,\n",
       " 'prediction': 1,\n",
       " 'british': 58,\n",
       " 'poised': 15,\n",
       " 'consider': 7,\n",
       " 'bill': 32,\n",
       " 'trumpism': 1,\n",
       " 'take': 87,\n",
       " 'deeper': 2,\n",
       " 'root': 7,\n",
       " 'hampshire': 13,\n",
       " 'thieves': 3,\n",
       " 'broke': 9,\n",
       " 'australian': 10,\n",
       " 'apple': 60,\n",
       " 'store': 18,\n",
       " 'sledgehammer': 1,\n",
       " 'worth': 21,\n",
       " 'may': 82,\n",
       " 'already': 6,\n",
       " 'nothing': 6,\n",
       " 'aapl': 26,\n",
       " 'openings': 6,\n",
       " 'experience': 11,\n",
       " 'menu': 8,\n",
       " 'nadal': 13,\n",
       " 'drops': 20,\n",
       " 'set': 73,\n",
       " 'advances': 6,\n",
       " 'last': 42,\n",
       " 'eight': 9,\n",
       " 'watch': 89,\n",
       " 'floodwaters': 2,\n",
       " 'dangerous': 10,\n",
       " 'responders': 1,\n",
       " 'james': 20,\n",
       " 'mitchell': 2,\n",
       " 'northampton': 1,\n",
       " 'saints': 6,\n",
       " 'sign': 26,\n",
       " 'connacht': 4,\n",
       " 'scrum': 1,\n",
       " 'half': 31,\n",
       " 'passengers': 11,\n",
       " 'werent': 4,\n",
       " 'wearing': 5,\n",
       " 'life': 59,\n",
       " 'jackets': 1,\n",
       " 'suspect': 27,\n",
       " 'fatally': 5,\n",
       " 'shot': 48,\n",
       " 'kaukauna': 1,\n",
       " 'huawei': 20,\n",
       " 'claims': 45,\n",
       " 'threatened': 13,\n",
       " 'employees': 21,\n",
       " 'attacked': 13,\n",
       " 'network': 9,\n",
       " 'ystalyfera': 1,\n",
       " 'landslide': 1,\n",
       " 'risk': 32,\n",
       " 'schools': 19,\n",
       " 'portable': 3,\n",
       " 'classroom': 3,\n",
       " 'defended': 3,\n",
       " 'postmaster': 1,\n",
       " 'retires': 4,\n",
       " 'absolutely': 3,\n",
       " 'brilliant': 4,\n",
       " 'made': 42,\n",
       " 'history': 30,\n",
       " 'michelle': 3,\n",
       " 'bachelet': 2,\n",
       " 'intense': 2,\n",
       " 'hurricanes': 7,\n",
       " 'cause': 11,\n",
       " 'damage': 19,\n",
       " 'â€˜genocide': 1,\n",
       " 'cardâ€™': 1,\n",
       " 'myanmar': 3,\n",
       " 'verification': 1,\n",
       " 'scheme': 8,\n",
       " 'condemned': 3,\n",
       " 'malibu': 4,\n",
       " 'hiker': 4,\n",
       " 'heat': 13,\n",
       " 'stroke': 2,\n",
       " 'others': 8,\n",
       " 'rescued': 8,\n",
       " 'water': 27,\n",
       " 'arsenal': 9,\n",
       " 'defence': 9,\n",
       " 'balance': 5,\n",
       " 'hard': 14,\n",
       " 'come': 19,\n",
       " 'sisyphus': 2,\n",
       " 'underlines': 2,\n",
       " 'coastal': 4,\n",
       " 'cities': 17,\n",
       " 'endless': 2,\n",
       " 'rebuilding': 5,\n",
       " 'task': 3,\n",
       " 'anak': 2,\n",
       " 'krakatau': 2,\n",
       " 'volcanos': 1,\n",
       " 'tsunami': 3,\n",
       " 'trigger': 2,\n",
       " 'relatively': 1,\n",
       " 'small': 22,\n",
       " 'mary': 4,\n",
       " 'robinson': 3,\n",
       " 'reminds': 4,\n",
       " 'global': 37,\n",
       " 'investors': 31,\n",
       " 'climate': 74,\n",
       " 'duty': 6,\n",
       " 'donald': 44,\n",
       " 'congratulates': 2,\n",
       " 'poland': 4,\n",
       " 'nation': 16,\n",
       " 'somber': 1,\n",
       " 'anniversary': 21,\n",
       " 'nazi': 7,\n",
       " 'invasion': 2,\n",
       " 'also': 15,\n",
       " 'many': 19,\n",
       " 'polish': 5,\n",
       " 'country': 24,\n",
       " 'mineral': 2,\n",
       " 'based': 9,\n",
       " 'sunscreen': 2,\n",
       " 'doesnt': 15,\n",
       " 'leave': 34,\n",
       " 'white': 61,\n",
       " 'residue': 1,\n",
       " 'behind': 30,\n",
       " 'protects': 3,\n",
       " 'familys': 2,\n",
       " 'fair': 6,\n",
       " 'skin': 7,\n",
       " 'reef': 2,\n",
       " 'friendly': 5,\n",
       " 'imitating': 1,\n",
       " 'stephen': 11,\n",
       " 'king': 18,\n",
       " 'art': 18,\n",
       " 'scares': 1,\n",
       " 'ethiopian': 7,\n",
       " 'opposition': 23,\n",
       " 'parties': 9,\n",
       " 'threaten': 9,\n",
       " 'boycott': 6,\n",
       " 'bullied': 6,\n",
       " 'dancing': 5,\n",
       " 'bossing': 1,\n",
       " 'britains': 10,\n",
       " 'got': 25,\n",
       " 'talents': 1,\n",
       " 'masked': 2,\n",
       " 'boeing': 17,\n",
       " 'shares': 31,\n",
       " 'slide': 10,\n",
       " 'max': 18,\n",
       " 'delay': 25,\n",
       " 'threatens': 18,\n",
       " 'holiday': 12,\n",
       " 'season': 32,\n",
       " 'ba': 7,\n",
       " 'kristen': 2,\n",
       " 'stewart': 3,\n",
       " 'reflects': 5,\n",
       " 'robert': 49,\n",
       " 'pattinson': 2,\n",
       " 'romance': 2,\n",
       " 'coming': 28,\n",
       " 'bosses': 4,\n",
       " 'reveal': 16,\n",
       " 'wish': 3,\n",
       " 'tell': 11,\n",
       " 'day': 92,\n",
       " 'terry': 2,\n",
       " 'gilliam': 2,\n",
       " 'disagree': 1,\n",
       " 'cleese': 1,\n",
       " 'iran': 82,\n",
       " 'nuclear': 36,\n",
       " 'violation': 1,\n",
       " 'send': 14,\n",
       " 'wrong': 22,\n",
       " 'signal': 5,\n",
       " 'french': 32,\n",
       " 'source': 34,\n",
       " 'havent': 4,\n",
       " 'gotten': 2,\n",
       " 'iphone': 44,\n",
       " 'heres': 101,\n",
       " 'cant': 19,\n",
       " 'wait': 5,\n",
       " 'buy': 36,\n",
       " 'yearslong': 1,\n",
       " 'tax': 40,\n",
       " 'dispute': 15,\n",
       " 'big': 80,\n",
       " 'companies': 39,\n",
       " 'billions': 4,\n",
       " 'wall': 126,\n",
       " 'street': 119,\n",
       " 'journal': 67,\n",
       " 'landfall': 8,\n",
       " 'florida': 51,\n",
       " 'east': 20,\n",
       " 'approved': 5,\n",
       " 'prorogation': 2,\n",
       " 'august': 32,\n",
       " 'edinburgh': 7,\n",
       " 'told': 28,\n",
       " 'raymond': 1,\n",
       " 'mccord': 1,\n",
       " 'chapter': 11,\n",
       " 'manages': 1,\n",
       " 'entertain': 1,\n",
       " 'hours': 23,\n",
       " 'huge': 10,\n",
       " 'box': 13,\n",
       " 'office': 36,\n",
       " 'hit': 72,\n",
       " 'feel': 16,\n",
       " 'familiar': 1,\n",
       " 'seeking': 8,\n",
       " '10m': 1,\n",
       " 'death': 108,\n",
       " 'toll': 23,\n",
       " 'jumps': 6,\n",
       " 'several': 10,\n",
       " 'german': 24,\n",
       " 'critic': 1,\n",
       " 'fat': 4,\n",
       " 'shaming': 2,\n",
       " 'soprano': 2,\n",
       " 'kathryn': 1,\n",
       " 'lewek': 1,\n",
       " 'shocking': 4,\n",
       " 'things': 35,\n",
       " 'teacher': 13,\n",
       " 'youd': 1,\n",
       " 'thought': 12,\n",
       " 'trumps': 105,\n",
       " 'blessing': 1,\n",
       " 'pompeo': 34,\n",
       " 'sought': 8,\n",
       " 'reset': 4,\n",
       " 'leaders': 30,\n",
       " 'envoy': 16,\n",
       " 'turn': 19,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_DF(tfDict):\n",
    "    count_DF = {}\n",
    "    # Run through each document's tf dictionary and increment countDict's (term, doc) pair\n",
    "    for document in tfDict:\n",
    "        for term in document:\n",
    "            if term in count_DF:\n",
    "                count_DF[term] += 1\n",
    "            else:\n",
    "                count_DF[term] = 1\n",
    "    return count_DF\n",
    "\n",
    "DF = calc_DF(dataset_1[\"TF_dict\"])\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung IDF\n",
    "n_document = len(dataset_1)\n",
    "\n",
    "def calc_IDF(__n_document, __DF):\n",
    "    IDF_Dict = {}\n",
    "    for term in __DF:\n",
    "        IDF_Dict[term] = np.log(__n_document / (__DF[term] + 1))\n",
    "    return IDF_Dict\n",
    "  \n",
    "#Stores the idf dictionary\n",
    "IDF = calc_IDF(n_document, DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc TF-IDF\n",
    "def calc_TF_IDF(TF):\n",
    "    TF_IDF_Dict = {}\n",
    "    #For each word in the review, we multiply its tf and its idf.\n",
    "    for key in TF:\n",
    "        TF_IDF_Dict[key] = TF[key] * IDF[key]\n",
    "    return TF_IDF_Dict\n",
    "\n",
    "#Stores the TF-IDF Series\n",
    "dataset_1[\"TF-IDF_dict\"] = dataset_1[\"TF_dict\"].apply(calc_TF_IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                term \t         TF \t              TF-IDF\n",
      "\n",
      "              gregor \t 0.14285714285714285 \t 1.1985448945837724\n",
      "            townsend \t 0.14285714285714285 \t 1.1985448945837724\n",
      "            believes \t 0.14285714285714285 \t 1.0995238687894944\n",
      "            scotland \t 0.14285714285714285 \t 0.7705831412189165\n",
      "               never \t 0.14285714285714285 \t 0.8215367046387354\n",
      "              better \t 0.14285714285714285 \t 0.8267320823774319\n",
      "            position \t 0.14285714285714285 \t 1.0195787562272913\n"
     ]
    }
   ],
   "source": [
    "# Check TF-IDF result\n",
    "index = 90\n",
    "\n",
    "print('%20s' % \"term\", \"\\t\", '%10s' % \"TF\", \"\\t\", '%20s' % \"TF-IDF\\n\")\n",
    "for key in dataset_1[\"TF-IDF_dict\"][index]:\n",
    "    print('%20s' % key, \"\\t\", dataset_1[\"TF_dict\"][index][key] ,\"\\t\" , dataset_1[\"TF-IDF_dict\"][index][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print first row matrix TF_IDF_Vec Series\n",
      "\n",
      "[0.0, 0.0, 0.0, 0.4277023667427866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "matrix size :  50\n"
     ]
    }
   ],
   "source": [
    "# sort descending by value for DF dictionary \n",
    "sorted_DF = sorted(DF.items(), key=lambda kv: kv[1], reverse=True)[:50]\n",
    "\n",
    "# Create a list of unique words from sorted dictionay `sorted_DF`\n",
    "unique_term = [item[0] for item in sorted_DF]\n",
    "\n",
    "def calc_TF_IDF_Vec(__TF_IDF_Dict):\n",
    "    TF_IDF_vector = [0.0] * len(unique_term)\n",
    "\n",
    "    # For each unique word, if it is in the review, store its TF-IDF value.\n",
    "    for i, term in enumerate(unique_term):\n",
    "        if term in __TF_IDF_Dict:\n",
    "            TF_IDF_vector[i] = __TF_IDF_Dict[term]\n",
    "    return TF_IDF_vector\n",
    "\n",
    "dataset_1[\"TF_IDF_Vec\"] = dataset_1[\"TF-IDF_dict\"].apply(calc_TF_IDF_Vec)\n",
    "\n",
    "print(\"print first row matrix TF_IDF_Vec Series\\n\")\n",
    "print(dataset_1[\"TF_IDF_Vec\"][0])\n",
    "\n",
    "print(\"\\nmatrix size : \", len(dataset_1[\"TF_IDF_Vec\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>gmt</td>\n",
       "      <td>407.425084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us</td>\n",
       "      <td>203.785911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trump</td>\n",
       "      <td>174.142940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new</td>\n",
       "      <td>169.452673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>says</td>\n",
       "      <td>151.907922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brexit</td>\n",
       "      <td>117.421807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man</td>\n",
       "      <td>97.864182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>world</td>\n",
       "      <td>91.607767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deal</td>\n",
       "      <td>80.335355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>year</td>\n",
       "      <td>79.982706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ireland</td>\n",
       "      <td>79.155497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>police</td>\n",
       "      <td>79.026771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>johnson</td>\n",
       "      <td>77.770063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>china</td>\n",
       "      <td>74.148575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dorian</td>\n",
       "      <td>71.136306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>one</td>\n",
       "      <td>69.475791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hurricane</td>\n",
       "      <td>68.955404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>latest</td>\n",
       "      <td>67.801934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>first</td>\n",
       "      <td>66.940704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>uk</td>\n",
       "      <td>66.467935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>house</td>\n",
       "      <td>65.742784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>death</td>\n",
       "      <td>64.250576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>could</td>\n",
       "      <td>63.335636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>saudi</td>\n",
       "      <td>62.637095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>dies</td>\n",
       "      <td>61.943205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>review</td>\n",
       "      <td>60.236210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hong</td>\n",
       "      <td>59.925356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>million</td>\n",
       "      <td>58.980829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>killed</td>\n",
       "      <td>57.637204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cup</td>\n",
       "      <td>57.584241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>kong</td>\n",
       "      <td>57.450278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>talks</td>\n",
       "      <td>56.824717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>wall</td>\n",
       "      <td>55.929139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>plan</td>\n",
       "      <td>55.045112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>street</td>\n",
       "      <td>54.776961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>court</td>\n",
       "      <td>53.747781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>get</td>\n",
       "      <td>53.699152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>like</td>\n",
       "      <td>52.210600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>york</td>\n",
       "      <td>52.034972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>trumps</td>\n",
       "      <td>52.023689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>irish</td>\n",
       "      <td>51.513586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>trade</td>\n",
       "      <td>51.086264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>years</td>\n",
       "      <td>50.695762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>day</td>\n",
       "      <td>50.606049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>back</td>\n",
       "      <td>49.561586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>oil</td>\n",
       "      <td>49.551265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>live</td>\n",
       "      <td>48.146691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>people</td>\n",
       "      <td>46.616694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>former</td>\n",
       "      <td>45.177895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>heres</td>\n",
       "      <td>41.421186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term        rank\n",
       "48        gmt  407.425084\n",
       "0          us  203.785911\n",
       "2       trump  174.142940\n",
       "1         new  169.452673\n",
       "3        says  151.907922\n",
       "4      brexit  117.421807\n",
       "5         man   97.864182\n",
       "6       world   91.607767\n",
       "8        deal   80.335355\n",
       "7        year   79.982706\n",
       "10    ireland   79.155497\n",
       "9      police   79.026771\n",
       "14    johnson   77.770063\n",
       "16      china   74.148575\n",
       "13     dorian   71.136306\n",
       "12        one   69.475791\n",
       "17  hurricane   68.955404\n",
       "25     latest   67.801934\n",
       "15      first   66.940704\n",
       "19         uk   66.467935\n",
       "22      house   65.742784\n",
       "28      death   64.250576\n",
       "11      could   63.335636\n",
       "24      saudi   62.637095\n",
       "32       dies   61.943205\n",
       "41     review   60.236210\n",
       "23       hong   59.925356\n",
       "21    million   58.980829\n",
       "34     killed   57.637204\n",
       "26        cup   57.584241\n",
       "27       kong   57.450278\n",
       "30      talks   56.824717\n",
       "18       wall   55.929139\n",
       "43       plan   55.045112\n",
       "20     street   54.776961\n",
       "35      court   53.747781\n",
       "38        get   53.699152\n",
       "29       like   52.210600\n",
       "40       york   52.034972\n",
       "31     trumps   52.023689\n",
       "47      irish   51.513586\n",
       "37      trade   51.086264\n",
       "44      years   50.695762\n",
       "45        day   50.606049\n",
       "42       back   49.561586\n",
       "39        oil   49.551265\n",
       "36       live   48.146691\n",
       "46     people   46.616694\n",
       "49     former   45.177895\n",
       "33      heres   41.421186"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Series to List\n",
    "TF_IDF_Vec_List = np.array(dataset_1[\"TF_IDF_Vec\"].to_list())\n",
    "\n",
    "# Sum element vector in axis=0 \n",
    "sums = TF_IDF_Vec_List.sum(axis=0)\n",
    "\n",
    "data = []\n",
    "\n",
    "for col, term in enumerate(unique_term):\n",
    "    data.append((term, sums[col]))\n",
    "    \n",
    "ranking = pd.DataFrame(data, columns=['term', 'rank'])\n",
    "ranking.sort_values('rank', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TF-IDF of Dataset 2</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Plot</th>\n",
       "      <th>Movie</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "      <td>['bartender', 'working', 'saloon', 'serving', ...</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "      <td>['moon', 'painted', 'smiling', 'face', 'hangs'...</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "      <td>['film', 'minute', 'long', 'composed', 'two', ...</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Terrible Teddy, the Grizzly King</td>\n",
       "      <td>Lasting just 61 seconds and consisting of two ...</td>\n",
       "      <td>['lasting', 'seconds', 'consisting', 'two', 's...</td>\n",
       "      <td>922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jack and the Beanstalk</td>\n",
       "      <td>The earliest known adaptation of the classic f...</td>\n",
       "      <td>['earliest', 'known', 'adaptation', 'classic',...</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title  \\\n",
       "0            Kansas Saloon Smashers   \n",
       "1     Love by the Light of the Moon   \n",
       "2           The Martyred Presidents   \n",
       "3  Terrible Teddy, the Grizzly King   \n",
       "4            Jack and the Beanstalk   \n",
       "\n",
       "                                                Plot  \\\n",
       "0  A bartender is working at a saloon, serving dr...   \n",
       "1  The moon, painted with a smiling face hangs ov...   \n",
       "2  The film, just over a minute long, is composed...   \n",
       "3  Lasting just 61 seconds and consisting of two ...   \n",
       "4  The earliest known adaptation of the classic f...   \n",
       "\n",
       "                                               Movie  length  \n",
       "0  ['bartender', 'working', 'saloon', 'serving', ...     522  \n",
       "1  ['moon', 'painted', 'smiling', 'face', 'hangs'...     466  \n",
       "2  ['film', 'minute', 'long', 'composed', 'two', ...     459  \n",
       "3  ['lasting', 'seconds', 'consisting', 'two', 's...     922  \n",
       "4  ['earliest', 'known', 'adaptation', 'classic',...     754  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chaplins', 'character', 'attempts', 'convince', 'passerby', 'director', 'henry', 'lehrman', 'give', 'money', 'chaplin', 'shown', 'flirting', 'woman', 'proposes', 'accepts', 'lehrman', 'enters', 'present', 'woman', 'flowers', 'ring', 'woman', 'refuses', 'citing', 'shes', 'engaged', 'lerhman', 'sees', 'chaplin', 'slapstick', 'fight', 'two', 'ensues', 'later', 'lehrmans', 'character', 'takes', 'photograph', 'automobile', 'accident', 'chaplins', 'character', 'steals', 'camera', 'whilst', 'journalist', 'helping', 'trapped', 'motorist', 'rushes', 'back', 'paper', 'claim', 'photograph', 'short', 'pursuit', 'keystone', 'kops', 'follows']\n",
      "\n",
      "type :  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# convert list formated string to list\n",
    "import ast\n",
    "\n",
    "def convert_text_list(texts):\n",
    "    texts = ast.literal_eval(texts)\n",
    "    return [text for text in texts]\n",
    "\n",
    "dataset_2[\"movie_list\"] = dataset_2[\"Movie\"].apply(convert_text_list)\n",
    "\n",
    "\n",
    "print(dataset_2[\"movie_list\"][90])\n",
    "\n",
    "print(\"\\ntype : \", type(dataset_2[\"movie_list\"][90]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'bartender': 0.041666666666666664, 'working':...\n",
       "1    {'moon': 0.06818181818181818, 'painted': 0.022...\n",
       "2    {'film': 0.023809523809523808, 'minute': 0.023...\n",
       "3    {'lasting': 0.011764705882352941, 'seconds': 0...\n",
       "4    {'earliest': 0.014084507042253521, 'known': 0....\n",
       "Name: TF_dict, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_TF(document):\n",
    "    # Counts the number of times the word appears in review\n",
    "    TF_dict = {}\n",
    "    for term in document:\n",
    "        if term in TF_dict:\n",
    "            TF_dict[term] += 1\n",
    "        else:\n",
    "            TF_dict[term] = 1\n",
    "    # Computes tf for each word\n",
    "    for term in TF_dict:\n",
    "        TF_dict[term] = TF_dict[term] / len(document)\n",
    "    return TF_dict\n",
    "\n",
    "dataset_2[\"TF_dict\"] = dataset_2['movie_list'].apply(calc_TF)\n",
    "\n",
    "dataset_2[\"TF_dict\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                term \t TF\n",
      "\n",
      "            chaplins \t 0.03333333333333333\n",
      "           character \t 0.05\n",
      "            attempts \t 0.016666666666666666\n",
      "            convince \t 0.016666666666666666\n",
      "            passerby \t 0.016666666666666666\n",
      "            director \t 0.016666666666666666\n",
      "               henry \t 0.016666666666666666\n",
      "             lehrman \t 0.03333333333333333\n",
      "                give \t 0.016666666666666666\n",
      "               money \t 0.016666666666666666\n",
      "             chaplin \t 0.03333333333333333\n",
      "               shown \t 0.016666666666666666\n",
      "            flirting \t 0.016666666666666666\n",
      "               woman \t 0.05\n",
      "            proposes \t 0.016666666666666666\n",
      "             accepts \t 0.016666666666666666\n",
      "              enters \t 0.016666666666666666\n",
      "             present \t 0.016666666666666666\n",
      "             flowers \t 0.016666666666666666\n",
      "                ring \t 0.016666666666666666\n",
      "             refuses \t 0.016666666666666666\n",
      "              citing \t 0.016666666666666666\n",
      "                shes \t 0.016666666666666666\n",
      "             engaged \t 0.016666666666666666\n",
      "             lerhman \t 0.016666666666666666\n",
      "                sees \t 0.016666666666666666\n",
      "           slapstick \t 0.016666666666666666\n",
      "               fight \t 0.016666666666666666\n",
      "                 two \t 0.016666666666666666\n",
      "              ensues \t 0.016666666666666666\n",
      "               later \t 0.016666666666666666\n",
      "            lehrmans \t 0.016666666666666666\n",
      "               takes \t 0.016666666666666666\n",
      "          photograph \t 0.03333333333333333\n",
      "          automobile \t 0.016666666666666666\n",
      "            accident \t 0.016666666666666666\n",
      "              steals \t 0.016666666666666666\n",
      "              camera \t 0.016666666666666666\n",
      "              whilst \t 0.016666666666666666\n",
      "          journalist \t 0.016666666666666666\n",
      "             helping \t 0.016666666666666666\n",
      "             trapped \t 0.016666666666666666\n",
      "            motorist \t 0.016666666666666666\n",
      "              rushes \t 0.016666666666666666\n",
      "                back \t 0.016666666666666666\n",
      "               paper \t 0.016666666666666666\n",
      "               claim \t 0.016666666666666666\n",
      "               short \t 0.016666666666666666\n",
      "             pursuit \t 0.016666666666666666\n",
      "            keystone \t 0.016666666666666666\n",
      "                kops \t 0.016666666666666666\n",
      "             follows \t 0.016666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Check TF result\n",
    "index = 90\n",
    "\n",
    "print('%20s' % \"term\", \"\\t\", \"TF\\n\")\n",
    "for key in dataset_2[\"TF_dict\"][index]:\n",
    "    print('%20s' % key, \"\\t\", dataset_2[\"TF_dict\"][index][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
